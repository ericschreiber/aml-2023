{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "import biosppy.signals.ecg as ecg\n",
    "import neurokit2\n",
    "import tsfel\n",
    "import emd\n",
    "import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from numpy.fft import rfft, irfft\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from scipy import stats\n",
    "from statistics import pstdev,variance\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from sktime.transformations.panel.rocket import MiniRocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"task2/X_train.csv\").drop('id', axis=1)\n",
    "y_train = pd.read_csv(\"task2/y_train.csv\").drop('id', axis=1)\n",
    "X_test = pd.read_csv(\"task2/X_test.csv\").drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = X_train.shape[0]\n",
    "n_cols = X_train.shape[1]\n",
    "\n",
    "dataset_x = X_train.copy()\n",
    "dataset_x = np.array(dataset_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biosppy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute some statistics of all the signals \n",
    "autocor = []\n",
    "ptp = []\n",
    "med = []\n",
    "avg = []\n",
    "fft=[]\n",
    "\n",
    "for i in range(n_rows):\n",
    "    signal = dataset_x[i]\n",
    "    signal_serie = pd.Series(signal)\n",
    "    corr = signal_serie.autocorr(lag=2)\n",
    "    autocor.append(corr)\n",
    "    #average, range, median\n",
    "    avg.append(np.average(signal))\n",
    "    ptp.append(np.ptp(signal))\n",
    "    med.append(np.median(signal))\n",
    "    #top 20 fft frequencies\n",
    "    f = np.fft.fft(signal)\n",
    "    array = f[0:800]\n",
    "    n = 20\n",
    "    indices = array.argsort()[-n:][::-1]\n",
    "    fft.append(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5117, 17807)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Padding the data in case some library need, padding with the last value. \n",
    "to_pad = n_cols\n",
    "new_seq = []\n",
    "for one_seq in dataset_x:\n",
    "    one_seq = one_seq[~np.isnan(one_seq)]\n",
    "    len_one_seq = len(one_seq)\n",
    "    last_val = one_seq[-1]\n",
    "    n = to_pad - len_one_seq\n",
    "    to_concat = np.repeat(0, n)\n",
    "    new_one_seq = np.concatenate([one_seq, to_concat])\n",
    "    new_seq.append(new_one_seq)\n",
    "padded = np.stack(new_seq)\n",
    "padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zheng\\AppData\\Local\\Temp\\ipykernel_27972\\408978776.py:84: RuntimeWarning: divide by zero encountered in divide\n",
      "  QRS_P_list= np.divide(QRS_list, P_list)\n",
      "c:\\Users\\zheng\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\zheng\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\zheng\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3747: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "c:\\Users\\zheng\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "c:\\Users\\zheng\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "#templates_ts: equal step timestep, axis reference\n",
    "#templates: #heartbeat * timestep \n",
    "#heart_rate_ts: heart_rate_ts, equal-step timestamp\n",
    "#heart_rate: heart rate at each time\n",
    "\n",
    "ts_list = []\n",
    "filtered_list=[]\n",
    "rpeaks_list=[]\n",
    "templates_ts_list=[]\n",
    "templates_list=[]\n",
    "heart_rate_ts_list=[]\n",
    "heart_rate_list=[]\n",
    "norm_average_heartbeat_list = [] #normalized average heartbeat of pacient\n",
    "\n",
    "for i in range(n_rows):\n",
    "    ts, filtered, rpeaks, templates_ts, templates, heart_rate_ts, heart_rate = ecg.ecg(signal=padded[i], sampling_rate=300.0, show=False)\n",
    "    ts_list.append(ts)\n",
    "    filtered_list.append(filtered)\n",
    "    rpeaks_list.append(rpeaks)\n",
    "    templates_ts_list.append(templates_ts)\n",
    "    templates_list.append(templates)\n",
    "    heart_rate_ts_list.append(heart_rate_ts)\n",
    "    heart_rate_list.append(heart_rate)\n",
    "    norm_template = normalize(templates)\n",
    "    norm_average_heartbeat_list.append(sum(norm_template)/len(norm_template))\n",
    "\n",
    "# Extarct all the peaks \n",
    "P_list=[]\n",
    "Q_list=[]\n",
    "R_list=[]\n",
    "S_list=[]\n",
    "T_list=[]\n",
    "\n",
    "for i in range(len(norm_average_heartbeat_list)):\n",
    "\n",
    "    patient_current = norm_average_heartbeat_list[i]\n",
    "\n",
    "    # Find the peak\n",
    "    index = np.where(patient_current==max(patient_current))\n",
    "    R = index[0]\n",
    "\n",
    "    # First-half\n",
    "    first_half = patient_current[0:R[0]]\n",
    "    index = np.where(patient_current==min(first_half[R[0]-30:R[0]]))\n",
    "    Q = index[0]\n",
    "\n",
    "    index = np.where(first_half[0:Q[0]]==max(first_half[0:Q[0]]))\n",
    "    P = index[0]\n",
    "\n",
    "    #Second half\n",
    "    second_half = patient_current[R[0]+1:] \n",
    "    index = np.where(patient_current==min(second_half[0:30]))\n",
    "    S = index[0]\n",
    "\n",
    "    second_half = second_half[S[0]-R[0]+1:]\n",
    "    index = np.where(patient_current==max(second_half))\n",
    "    T = index[0] \n",
    "\n",
    "    P_list.append(P[0])\n",
    "    Q_list.append(Q[0])\n",
    "    R_list.append(R[0])\n",
    "    S_list.append(S[0])\n",
    "    T_list.append(T[0])\n",
    "\n",
    "# Intervals and Ratios of peaks\n",
    "PR_list = []\n",
    "QRS_list = []\n",
    "ST_list = []\n",
    "\n",
    "for i in range(len(P_list)):\n",
    "    PR_list.append(R_list[i]-P_list[i])\n",
    "    QRS_list.append(S_list[i]-Q_list[i])\n",
    "    ST_list.append(T_list[i]-S_list[i])\n",
    "\n",
    "PR_list = np.array(PR_list).reshape(-1,1)\n",
    "QRS_list = np.array(QRS_list).reshape(-1,1)\n",
    "ST_list = np.array(ST_list).reshape(-1,1)\n",
    "P_list = np.array(P_list).reshape(-1,1)\n",
    "R_list = np.array(R_list).reshape(-1,1)\n",
    "S_list = np.array(S_list).reshape(-1,1)\n",
    "T_list = np.array(T_list).reshape(-1,1)\n",
    "\n",
    "QRS_T_list= np.divide(QRS_list, T_list) \n",
    "QRS_P_list= np.divide(QRS_list, P_list) \n",
    "QRS_T_list=np.nan_to_num(QRS_T_list, nan=0.0,posinf=0.0, neginf=0.0)\n",
    "QRS_P_list=np.nan_to_num(QRS_P_list, nan=0.0,posinf=0.0, neginf=0.0)\n",
    "\n",
    "#statistics of heartrate and heartbeat\n",
    "hr_mean_list = []\n",
    "hr_median_list = []\n",
    "hr_var_list = []\n",
    "for i in range(len(heart_rate_list)):\n",
    "        hr_mean_list.append(np.mean(heart_rate_list[i]))\n",
    "        hr_median_list.append(np.median(heart_rate_list[i]))\n",
    "        hr_var_list.append(np.var(heart_rate_list[i]))\n",
    "hb_mean_list = []\n",
    "hb_median_list = []\n",
    "hb_var_list = []\n",
    "for i in range(len(norm_average_heartbeat_list)):\n",
    "        hb_mean_list.append(np.mean(norm_average_heartbeat_list[i]))\n",
    "        hb_median_list.append(np.median(norm_average_heartbeat_list[i]))\n",
    "        hb_var_list.append(np.var(norm_average_heartbeat_list[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time series libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rocket features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsfel features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emd features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neorokit features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
