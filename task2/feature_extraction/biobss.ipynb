{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/antropy/fractal.py:197: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @jit('float64(float64[:], int32)')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tqdm\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from util import load_base_data\n",
    "\n",
    "import biobss\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import neurokit2\n",
    "\n",
    "SAMPLING_RATE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test = load_base_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean signal length:  17807.0 min length:  17807\n"
     ]
    }
   ],
   "source": [
    "def mean_signal(signal):\n",
    "    # cut the signal to the length of the shortest signal\n",
    "    signal = np.array(signal)\n",
    "    min_length = min([len(s) for s in signal])\n",
    "    mean_length = np.mean([len(s) for s in signal])\n",
    "    print(\"Mean signal length: \", mean_length, \"min length: \", min_length)\n",
    "    signal = [s[:min_length] for s in signal]\n",
    "    return np.mean(signal, axis=0)\n",
    "\n",
    "\n",
    "mean_train_ecg = mean_signal(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loc_peaks(ecg):\n",
    "    # filtered_ecg=biobss.preprocess.filter_signal(sig, sampling_rate=SAMPLING_RATE, signal_type='ECG', method='pantompkins')\n",
    "    locs_peaks = biobss.ecgtools.ecg_detectpeaks(ecg, SAMPLING_RATE, \"pantompkins\")\n",
    "    # peaks = ecg[locs_peaks]\n",
    "    # info = biobss.sqatools.check_phys(locs_peaks, SAMPLING_RATE)\n",
    "    return locs_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_difference_to_mean(ecg, mean_ecg):\n",
    "    loc_peaks = get_loc_peaks(mean_ecg)\n",
    "    info = biobss.sqatools.template_matching(ecg, loc_peaks)\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features_based_on_difference_to_mean(ecg, mean_ecg):\n",
    "    info = check_difference_to_mean(ecg, mean_ecg)\n",
    "    # compute the mean, median and std of the correlation coefficients of the peaks compared to the mean signal\n",
    "    mean = np.mean(info[0])\n",
    "    median = np.median(info[0])\n",
    "    std = np.std(info[0])\n",
    "    return mean, median, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fiducials(ecg, loc_peaks):\n",
    "    _, fiducials = neurokit2.ecg_delineate(\n",
    "        ecg_cleaned=ecg, rpeaks=loc_peaks, sampling_rate=SAMPLING_RATE, method=\"peak\"\n",
    "    )\n",
    "\n",
    "    # p_peaks_locs = fiducials[\"ECG_P_Peaks\"]\n",
    "    # q_peaks_locs = fiducials[\"ECG_Q_Peaks\"]\n",
    "    # s_peaks_locs = fiducials[\"ECG_S_Peaks\"]\n",
    "    # t_peaks_locs = fiducials[\"ECG_T_Peaks\"]\n",
    "    # p_onset_locs = fiducials[\"ECG_P_Onsets\"]\n",
    "    # t_offset_locs = fiducials[\"ECG_T_Offsets\"]\n",
    "    return fiducials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features_rpeaks(ecg):\n",
    "    loc_peaks = get_loc_peaks(ecg)\n",
    "    features_rpeaks = biobss.ecgtools.ecg_features.from_Rpeaks(\n",
    "        ecg, loc_peaks, SAMPLING_RATE, average=False  # take the mean outside\n",
    "    )\n",
    "    return features_rpeaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features_from_P_Q_R_S_T(ecg):\n",
    "    loc_peaks = get_loc_peaks(ecg)\n",
    "    fiducials = get_fiducials(ecg, loc_peaks)\n",
    "    features = biobss.ecgtools.ecg_features.from_waves(\n",
    "        ecg, loc_peaks, fiducials, SAMPLING_RATE, average=False  # Take the mean outside\n",
    "    )\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_based_on_difference_to_mean_test = (\n",
    "    calculate_features_based_on_difference_to_mean(X_train.iloc[0], mean_train_ecg)\n",
    ")\n",
    "features_rpeaks_test = compute_features_rpeaks(X_train.iloc[0])\n",
    "features_from_P_Q_R_S_T_test = compute_features_from_P_Q_R_S_T(X_train.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_result(result):\n",
    "    \"\"\"input is a dict of dicts. Average over all the not nan values\n",
    "       an example is\n",
    "       1: {'ecg_a_R': -147.0,\n",
    "     'ecg_RR0': 0.36666666666666664,\n",
    "     'ecg_RR1': 0.84,\n",
    "     'ecg_RR2': 0.7766666666666666,\n",
    "     'ecg_RRm': 0.6611111111111111,\n",
    "     'ecg_RR_0_1': 0.4365079365079365,\n",
    "     'ecg_RR_2_1': 0.9246031746031745,\n",
    "     'ecg_RR_m_1': 0.7870370370370371},\n",
    "    2: {'ecg_a_R': -69.0,\n",
    "     'ecg_RR0': 0.84,\n",
    "     'ecg_RR1': 0.7766666666666666,\n",
    "     'ecg_RR2': 0.89,\n",
    "     'ecg_RRm': 0.8355555555555556,\n",
    "     'ecg_RR_0_1': 1.0815450643776825,\n",
    "     'ecg_RR_2_1': 1.145922746781116,\n",
    "     'ecg_RR_m_1': 1.0758226037195995},\"\"\"\n",
    "    number_of_results = sorted(list(result.keys()))\n",
    "\n",
    "    if len(number_of_results) <= 0:\n",
    "        print(\"No results to average over\")\n",
    "        print(result)\n",
    "        return [], []\n",
    "    # get all keys\n",
    "    keys = list(result[number_of_results[0]].keys())\n",
    "    # create a dict with empty lists\n",
    "    averaged_result = {key: [] for key in keys}\n",
    "    std_result = {key: [] for key in keys}\n",
    "    # iterate over all the results\n",
    "    for index in number_of_results:\n",
    "        r = result[index]\n",
    "        # iterate over all the keys\n",
    "        for key in keys:\n",
    "            # if the value is not nan\n",
    "            if not np.isnan(r[key]):\n",
    "                # append it to the list\n",
    "                averaged_result[key].append(r[key])\n",
    "    # compute the mean of all the values\n",
    "    for key in keys:\n",
    "        std_result[key] = np.std(averaged_result[key])\n",
    "        averaged_result[key] = np.mean(averaged_result[key])\n",
    "\n",
    "    # sort the keys alphabetically and return a list of the values and a list of the keys\n",
    "    sorted_keys = sorted(averaged_result.keys())\n",
    "\n",
    "    # rename key to mean_key and std_key\n",
    "    return_keys = []\n",
    "    for key in sorted_keys:\n",
    "        return_keys.append(key + \"_mean\")\n",
    "        return_keys.append(key + \"_std\")\n",
    "\n",
    "    return_values = []\n",
    "    for key in sorted_keys:\n",
    "        return_values.append(averaged_result[key])\n",
    "        return_values.append(std_result[key])\n",
    "    return return_values, return_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.8164583333333333,\n",
       "  0.06360106513346385,\n",
       "  0.8236458333333333,\n",
       "  0.028877848284243373,\n",
       "  0.8232291666666667,\n",
       "  0.028831218311156325,\n",
       "  0.9921928659291079,\n",
       "  0.07982498319270012,\n",
       "  1.0002605372265776,\n",
       "  0.03958271714975402,\n",
       "  0.9974844677185619,\n",
       "  0.034642660812381286,\n",
       "  0.8211111111111111,\n",
       "  0.0299607510743351,\n",
       "  -22.984375,\n",
       "  143.15054271940213],\n",
       " ['ecg_RR0_mean',\n",
       "  'ecg_RR0_std',\n",
       "  'ecg_RR1_mean',\n",
       "  'ecg_RR1_std',\n",
       "  'ecg_RR2_mean',\n",
       "  'ecg_RR2_std',\n",
       "  'ecg_RR_0_1_mean',\n",
       "  'ecg_RR_0_1_std',\n",
       "  'ecg_RR_2_1_mean',\n",
       "  'ecg_RR_2_1_std',\n",
       "  'ecg_RR_m_1_mean',\n",
       "  'ecg_RR_m_1_std',\n",
       "  'ecg_RRm_mean',\n",
       "  'ecg_RRm_std',\n",
       "  'ecg_a_R_mean',\n",
       "  'ecg_a_R_std'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_result(features_rpeaks_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_features(ecg_pandas, mean_train_ecg):\n",
    "    ecg_array = ecg_pandas.to_numpy()\n",
    "    print(ecg_array[0].shape)\n",
    "\n",
    "    feature_names = [\n",
    "        \"Mean correlation to the average signal\",\n",
    "        \"Median correlation to the average signal\",\n",
    "        \"Std correlation to the average signal\",\n",
    "    ]\n",
    "    feature_names = (\n",
    "        feature_names + average_result(compute_features_rpeaks(ecg_array[0]))[1]\n",
    "    )\n",
    "    feature_names = (\n",
    "        feature_names + average_result(compute_features_from_P_Q_R_S_T(ecg_array[0]))[1]\n",
    "    )\n",
    "\n",
    "    num_features_for_rpeaks = len(\n",
    "        average_result(compute_features_rpeaks(ecg_array[0]))[1]\n",
    "    )\n",
    "    num_features_for_P_Q_R_S_T = len(\n",
    "        average_result(compute_features_from_P_Q_R_S_T(ecg_array[0]))[1]\n",
    "    )\n",
    "\n",
    "    mean_ecg = mean_train_ecg\n",
    "    features_based_on_difference_to_mean = []\n",
    "    features_rpeaks = []\n",
    "    features_from_P_Q_R_S_T = []\n",
    "\n",
    "    # construct default 0 values to insert if there is an error\n",
    "    names_rpeaks = average_result(compute_features_rpeaks(ecg_array[0]))[1]\n",
    "    default_rpeaks = (np.zeros(len(names_rpeaks)), names_rpeaks)\n",
    "    names_P_Q_R_S_T = average_result(compute_features_from_P_Q_R_S_T(ecg_array[0]))[1]\n",
    "    default_P_Q_R_S_T = (np.zeros(len(names_P_Q_R_S_T)), names_P_Q_R_S_T)\n",
    "\n",
    "    for index, ecg in tqdm.tqdm(enumerate(ecg_array)):\n",
    "        # MEAN\n",
    "        features_based_on_difference_to_mean.append(\n",
    "            calculate_features_based_on_difference_to_mean(ecg, mean_ecg)\n",
    "        )\n",
    "\n",
    "        # RPEAKS\n",
    "        interim_features_rpeaks = average_result(compute_features_rpeaks(ecg))\n",
    "        if len(interim_features_rpeaks[1]) != num_features_for_rpeaks:\n",
    "            print(\n",
    "                f\"ERROR: Number of features for rpeaks is not consistent, {index} will be 0\"\n",
    "            )\n",
    "            interim_features_rpeaks = default_rpeaks\n",
    "        features_rpeaks.append(interim_features_rpeaks[0])\n",
    "\n",
    "        # P_Q_R_S_T\n",
    "        try:\n",
    "            interim_features_from_P_Q_R_S_T = average_result(\n",
    "                compute_features_from_P_Q_R_S_T(ecg)\n",
    "            )\n",
    "            if len(interim_features_from_P_Q_R_S_T[1]) != num_features_for_P_Q_R_S_T:\n",
    "                print(\n",
    "                    f\"ERROR: Number of features for P_Q_R_S_T is not consistent, {index} will be 0\"\n",
    "                )\n",
    "                interim_features_from_P_Q_R_S_T = default_P_Q_R_S_T\n",
    "        except:\n",
    "            print(\n",
    "                f\"ERROR: Number of features for P_Q_R_S_T is not consistent, {index} will be 0\"\n",
    "            )\n",
    "            interim_features_from_P_Q_R_S_T = default_P_Q_R_S_T\n",
    "        features_from_P_Q_R_S_T.append(interim_features_from_P_Q_R_S_T[0])\n",
    "\n",
    "    # make np array\n",
    "    features_based_on_difference_to_mean = np.array(\n",
    "        features_based_on_difference_to_mean\n",
    "    )\n",
    "    features_rpeaks = np.array(features_rpeaks)\n",
    "    features_from_P_Q_R_S_T = np.array(features_from_P_Q_R_S_T)\n",
    "\n",
    "    return (\n",
    "        np.concatenate(\n",
    "            (\n",
    "                features_based_on_difference_to_mean,\n",
    "                features_rpeaks,\n",
    "                features_from_P_Q_R_S_T,\n",
    "            ),\n",
    "            axis=1,\n",
    "        ),\n",
    "        feature_names,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17807,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  4.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 2.72666876e-01,  2.78979461e-01,  3.24436380e-01,\n",
       "          8.16458333e-01,  6.36010651e-02,  8.23645833e-01,\n",
       "          2.88778483e-02,  8.23229167e-01,  2.88312183e-02,\n",
       "          9.92192866e-01,  7.98249832e-02,  1.00026054e+00,\n",
       "          3.95827171e-02,  9.97484468e-01,  3.46426608e-02,\n",
       "          8.21111111e-01,  2.99607511e-02, -2.29843750e+01,\n",
       "          1.43150543e+02, -1.50303030e+02,  1.36208727e+02,\n",
       "          9.04253571e-01,  5.77364717e-01,  1.90349863e+00,\n",
       "          2.92669222e+01,  1.29132402e+01,  8.13911554e+01,\n",
       "         -1.23619045e-01,  3.34376035e+00,  2.49982043e+00,\n",
       "          7.72055974e+00, -1.70838710e+02,  1.49281850e+02,\n",
       "          1.32644068e+02,  1.58040304e+02,  5.08636364e+01,\n",
       "          1.46347230e+02, -1.66935484e+01,  4.26677293e+01,\n",
       "          2.82152542e+02,  8.50441189e+01, -6.75555556e+01,\n",
       "          1.41062046e+02,  1.03567758e+00,  8.38101046e+00,\n",
       "          3.75615526e-01,  8.74806200e+00, -2.19690892e-01,\n",
       "          5.34801962e-01,  2.98033333e+02,  8.65967603e+01,\n",
       "         -2.73051990e+00,  1.23283225e+00, -8.17404807e+00,\n",
       "          7.20072390e+01,  9.85667715e-01,  5.22262465e-01,\n",
       "          8.30808081e-02,  2.94238194e-02,  1.64949495e-01,\n",
       "          4.02987264e-02,  2.37365591e-01,  8.69044239e-02,\n",
       "          4.14519774e-01,  5.10446897e-02,  3.38391228e+00,\n",
       "          1.25615848e+00,  8.18686869e-02,  2.60285313e-02,\n",
       "          1.53494624e-01,  9.10756655e-02,  3.29717514e-01,\n",
       "          4.47646624e-02,  2.66919467e+00,  9.70795339e-01,\n",
       "          7.24338624e-02,  8.93168396e-02,  2.48055556e-01,\n",
       "          3.75415408e-02,  1.84166667e-01,  4.84371490e-02],\n",
       "        [ 1.84545384e-01,  2.42230166e-01,  2.74690993e-01,\n",
       "          7.69411765e-01,  1.02151594e-01,  7.86470588e-01,\n",
       "          7.10377842e-02,  7.89313725e-01,  7.23769156e-02,\n",
       "          9.86294710e-01,  1.59648317e-01,  1.01151487e+00,\n",
       "          1.28107282e-01,  9.99269860e-01,  8.03277471e-02,\n",
       "          7.81732026e-01,  4.91623304e-02, -6.59411765e+01,\n",
       "          1.42622278e+02, -2.42794118e+02,  1.51984283e+02,\n",
       "          1.99212342e+00,  3.39219821e+00, -5.36505758e-01,\n",
       "          2.37725312e+00, -1.87893292e+00,  6.90021485e+00,\n",
       "         -1.53787969e+00,  2.86729499e+00, -1.73686435e-01,\n",
       "          2.45430804e+01, -1.71000000e+02,  1.61343353e+02,\n",
       "         -1.01035714e+02,  1.73679813e+02,  2.58611111e+01,\n",
       "          1.57593209e+02,  7.69090909e+01,  1.42791300e+02,\n",
       "          1.51413793e+02,  1.55207651e+02,  4.15294118e+01,\n",
       "          1.27935700e+02, -8.99865312e-01,  9.29078848e-01,\n",
       "          8.90243659e-01,  3.38076872e+00,  5.73515669e-01,\n",
       "          1.40155507e+00,  7.45333333e+01,  5.20453221e+01,\n",
       "         -4.76280385e-01,  5.70581756e-01,  9.02298017e-01,\n",
       "          3.16005551e+00,  5.16253107e-01,  5.00615810e-01,\n",
       "          6.99019608e-02,  4.23761964e-02,  1.35882353e-01,\n",
       "          4.86084719e-02,  3.17204301e-01,  1.09975875e-01,\n",
       "          3.78809524e-01,  9.50238662e-02,  1.82200983e+00,\n",
       "          5.74062475e-01,  7.06481481e-02,  2.95628588e-02,\n",
       "          2.58181818e-01,  1.11304148e-01,  3.15402299e-01,\n",
       "          9.32980795e-02,  1.43161145e+00,  3.17189043e-01,\n",
       "          1.82549020e-01,  1.06449100e-01,  2.38222222e-01,\n",
       "          9.11804614e-02,  7.77777778e-02,  3.97895699e-02]]),\n",
       " ['Mean correlation to the average signal',\n",
       "  'Median correlation to the average signal',\n",
       "  'Std correlation to the average signal',\n",
       "  'ecg_RR0_mean',\n",
       "  'ecg_RR0_std',\n",
       "  'ecg_RR1_mean',\n",
       "  'ecg_RR1_std',\n",
       "  'ecg_RR2_mean',\n",
       "  'ecg_RR2_std',\n",
       "  'ecg_RR_0_1_mean',\n",
       "  'ecg_RR_0_1_std',\n",
       "  'ecg_RR_2_1_mean',\n",
       "  'ecg_RR_2_1_std',\n",
       "  'ecg_RR_m_1_mean',\n",
       "  'ecg_RR_m_1_std',\n",
       "  'ecg_RRm_mean',\n",
       "  'ecg_RRm_std',\n",
       "  'ecg_a_R_mean',\n",
       "  'ecg_a_R_std',\n",
       "  'ecg_a_PQ_mean',\n",
       "  'ecg_a_PQ_std',\n",
       "  'ecg_a_PQ_PS_mean',\n",
       "  'ecg_a_PQ_PS_std',\n",
       "  'ecg_a_PQ_QR_mean',\n",
       "  'ecg_a_PQ_QR_std',\n",
       "  'ecg_a_PQ_QS_mean',\n",
       "  'ecg_a_PQ_QS_std',\n",
       "  'ecg_a_PQ_QT_mean',\n",
       "  'ecg_a_PQ_QT_std',\n",
       "  'ecg_a_PQ_RS_mean',\n",
       "  'ecg_a_PQ_RS_std',\n",
       "  'ecg_a_PS_mean',\n",
       "  'ecg_a_PS_std',\n",
       "  'ecg_a_PT_mean',\n",
       "  'ecg_a_PT_std',\n",
       "  'ecg_a_QR_mean',\n",
       "  'ecg_a_QR_std',\n",
       "  'ecg_a_QS_mean',\n",
       "  'ecg_a_QS_std',\n",
       "  'ecg_a_QT_mean',\n",
       "  'ecg_a_QT_std',\n",
       "  'ecg_a_RS_mean',\n",
       "  'ecg_a_RS_std',\n",
       "  'ecg_a_RS_QR_mean',\n",
       "  'ecg_a_RS_QR_std',\n",
       "  'ecg_a_RS_QS_mean',\n",
       "  'ecg_a_RS_QS_std',\n",
       "  'ecg_a_RS_QT_mean',\n",
       "  'ecg_a_RS_QT_std',\n",
       "  'ecg_a_ST_mean',\n",
       "  'ecg_a_ST_std',\n",
       "  'ecg_a_ST_PQ_mean',\n",
       "  'ecg_a_ST_PQ_std',\n",
       "  'ecg_a_ST_QS_mean',\n",
       "  'ecg_a_ST_QS_std',\n",
       "  'ecg_a_ST_QT_mean',\n",
       "  'ecg_a_ST_QT_std',\n",
       "  'ecg_t_PQ_mean',\n",
       "  'ecg_t_PQ_std',\n",
       "  'ecg_t_PR_mean',\n",
       "  'ecg_t_PR_std',\n",
       "  'ecg_t_PS_mean',\n",
       "  'ecg_t_PS_std',\n",
       "  'ecg_t_PT_mean',\n",
       "  'ecg_t_PT_std',\n",
       "  'ecg_t_PT_QS_mean',\n",
       "  'ecg_t_PT_QS_std',\n",
       "  'ecg_t_QR_mean',\n",
       "  'ecg_t_QR_std',\n",
       "  'ecg_t_QS_mean',\n",
       "  'ecg_t_QS_std',\n",
       "  'ecg_t_QT_mean',\n",
       "  'ecg_t_QT_std',\n",
       "  'ecg_t_QT_QS_mean',\n",
       "  'ecg_t_QT_QS_std',\n",
       "  'ecg_t_RS_mean',\n",
       "  'ecg_t_RS_std',\n",
       "  'ecg_t_RT_mean',\n",
       "  'ecg_t_RT_std',\n",
       "  'ecg_t_ST_mean',\n",
       "  'ecg_t_ST_std'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_all_features(X_train.iloc[0:2], mean_train_ecg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17807,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76it [00:12,  6.02it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "83it [00:14,  5.35it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/neurokit2/signal/signal_period.py:60: NeuroKitWarning: Too few peaks detected to compute the rate. Returning empty vector.\n",
      "  warn(\n",
      "85it [00:14,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results to average over\n",
      "{}\n",
      "ERROR: Number of features for rpeaks is not consistent, 83 will be 0\n",
      "ERROR: Number of features for P_Q_R_S_T is not consistent, 83 will be 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "105it [00:17,  5.04it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "429it [01:11,  6.68it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/neurokit2/signal/signal_period.py:60: NeuroKitWarning: Too few peaks detected to compute the rate. Returning empty vector.\n",
      "  warn(\n",
      "431it [01:11,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results to average over\n",
      "{}\n",
      "ERROR: Number of features for rpeaks is not consistent, 429 will be 0\n",
      "ERROR: Number of features for P_Q_R_S_T is not consistent, 429 will be 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "771it [02:08,  8.08it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/neurokit2/signal/signal_period.py:60: NeuroKitWarning: Too few peaks detected to compute the rate. Returning empty vector.\n",
      "  warn(\n",
      "773it [02:08,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results to average over\n",
      "{}\n",
      "ERROR: Number of features for rpeaks is not consistent, 771 will be 0\n",
      "ERROR: Number of features for P_Q_R_S_T is not consistent, 771 will be 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1046it [02:55,  8.39it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "1352it [03:49,  6.14it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "1870it [05:17,  4.95it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "2712it [07:39,  4.68it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "2818it [07:57,  6.30it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "3060it [08:37,  7.10it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "3245it [09:08,  5.17it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "3424it [09:38,  4.80it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/neurokit2/signal/signal_period.py:60: NeuroKitWarning: Too few peaks detected to compute the rate. Returning empty vector.\n",
      "  warn(\n",
      "3426it [09:38,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results to average over\n",
      "{}\n",
      "ERROR: Number of features for rpeaks is not consistent, 3424 will be 0\n",
      "ERROR: Number of features for P_Q_R_S_T is not consistent, 3424 will be 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3667it [10:21,  5.56it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "4023it [11:21,  5.77it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "4163it [11:44,  4.62it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/neurokit2/signal/signal_period.py:60: NeuroKitWarning: Too few peaks detected to compute the rate. Returning empty vector.\n",
      "  warn(\n",
      "4165it [11:45,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results to average over\n",
      "{}\n",
      "ERROR: Number of features for rpeaks is not consistent, 4163 will be 0\n",
      "ERROR: Number of features for P_Q_R_S_T is not consistent, 4163 will be 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5117it [14:24,  5.92it/s]\n"
     ]
    }
   ],
   "source": [
    "features_X_train, feature_names = make_all_features(X_train, mean_train_ecg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5117, 81)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_X_train.shape\n",
    "# feature_names\n",
    "# droped_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the data for inf and nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of infs: 2842\n",
      "Columns with infs: 13\n",
      "Number of values bigger than 10000: 840\n",
      "Number of values smaller than -10000: 2002\n",
      "Number of nans: 3210\n",
      "Columns with nans: 58\n"
     ]
    }
   ],
   "source": [
    "# How many infs\n",
    "print(f\"Number of infs: {np.sum(np.isinf(features_X_train))}\")\n",
    "# Which columns have infs\n",
    "cols_with_infs = np.where(np.isinf(features_X_train))[1]\n",
    "cols_with_infs_unique = np.unique(cols_with_infs)\n",
    "print(f\"Columns with infs: {len(cols_with_infs_unique)}\")\n",
    "# Numbers bigger than 10000\n",
    "print(f\"Number of values bigger than 10000: {np.sum(features_X_train > 10000)}\")\n",
    "# Cap everything bigger than 10000 to 10000\n",
    "features_X_train[features_X_train > 10000] = 10000\n",
    "# Numbers smaller than -10000\n",
    "print(f\"Number of values smaller than -10000: {np.sum(features_X_train < -10000)}\")\n",
    "# Cap everything smaller than -10000 to -10000\n",
    "features_X_train[features_X_train < -10000] = -10000\n",
    "# Cap inf to 20000\n",
    "features_X_train[np.isinf(features_X_train)] = 20000\n",
    "# Cap -inf to -20000\n",
    "features_X_train[np.isneginf(features_X_train)] = -20000\n",
    "\n",
    "# How many nans\n",
    "print(f\"Number of nans: {np.sum(np.isnan(features_X_train))}\")\n",
    "# Which columns have nans\n",
    "cols_with_nans = np.where(np.isnan(features_X_train))[1]\n",
    "cols_with_nans_unique = np.unique(cols_with_nans)\n",
    "print(f\"Columns with nans: {len(cols_with_nans_unique)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_droped = y_train.drop(droped_indices)\n",
    "# # reset the index\n",
    "# y_train_droped = y_train_droped.reset_index(drop=True)\n",
    "# # name the index column id\n",
    "# y_train_droped.index.name = \"id\"\n",
    "\n",
    "# DONT NEED TO DROP ANYTHING BECAUSE IS 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the features to a csv file\n",
    "df = pd.DataFrame(features_X_train, columns=feature_names)\n",
    "X_train_save_path = \"/Users/ericschreiber/dev/ETH/AML/Project_1/aml-2023/task2/data/feature_extraction/bioss_X_train.csv\"\n",
    "df.index.name = \"id\"\n",
    "df.to_csv(X_train_save_path, index=True)\n",
    "y_train_save_path = \"/Users/ericschreiber/dev/ETH/AML/Project_1/aml-2023/task2/data/feature_extraction/bioss_y_train.csv\"\n",
    "y_train.to_csv(y_train_save_path, index=True)\n",
    "# droped_indices_save_path = \"/Users/ericschreiber/dev/ETH/AML/Project_1/aml-2023/task2/data/feature_extraction/bioss_droped_indices_train.csv\"\n",
    "# dropped_rows = pd.DataFrame(droped_indices)\n",
    "# dropped_rows.to_csv(droped_indices_save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17807,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "402it [01:06,  5.03it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "640it [01:45,  6.15it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "741it [02:03,  5.42it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "747it [02:04,  6.01it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/neurokit2/signal/signal_period.py:60: NeuroKitWarning: Too few peaks detected to compute the rate. Returning empty vector.\n",
      "  warn(\n",
      "749it [02:04,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results to average over\n",
      "{}\n",
      "ERROR: Number of features for rpeaks is not consistent, 747 will be 0\n",
      "ERROR: Number of features for P_Q_R_S_T is not consistent, 747 will be 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "819it [02:15,  6.88it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "1186it [03:18,  4.64it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "1685it [04:43,  6.34it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "1979it [05:35,  6.23it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "2032it [05:45,  3.51it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/neurokit2/signal/signal_period.py:60: NeuroKitWarning: Too few peaks detected to compute the rate. Returning empty vector.\n",
      "  warn(\n",
      "2034it [05:45,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results to average over\n",
      "{}\n",
      "ERROR: Number of features for rpeaks is not consistent, 2032 will be 0\n",
      "ERROR: Number of features for P_Q_R_S_T is not consistent, 2032 will be 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2327it [06:36,  4.81it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/neurokit2/signal/signal_period.py:60: NeuroKitWarning: Too few peaks detected to compute the rate. Returning empty vector.\n",
      "  warn(\n",
      "2329it [06:36,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results to average over\n",
      "{}\n",
      "ERROR: Number of features for rpeaks is not consistent, 2327 will be 0\n",
      "ERROR: Number of features for P_Q_R_S_T is not consistent, 2327 will be 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2392it [06:48,  5.87it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "2709it [07:44,  5.50it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "3311it [09:26,  6.68it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "3356it [09:33,  6.66it/s]/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ericschreiber/miniconda3/envs/ml/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "3411it [09:43,  5.85it/s]\n"
     ]
    }
   ],
   "source": [
    "features_X_test, feature_names_test = make_all_features(X_test, mean_train_ecg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_X_test_double = features_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We need to add the dropped indices to the test indices. We fill those rows with zeros\n",
    "\n",
    "# droped_indices_test.sort(\n",
    "#     reverse=True\n",
    "# )  # we need to fill the indices from the back otherwise the indices will be wrong\n",
    "# for index in droped_indices_test:\n",
    "#     features_X_test = np.insert(features_X_test, index, 0, axis=0)\n",
    "\n",
    "# NO NEED TO DROP ANYTHING BECAUSE IS 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of infs: 2002\n",
      "Columns with infs: 13\n",
      "Number of values bigger than 10000: 601\n",
      "Number of values smaller than -10000: 1401\n"
     ]
    }
   ],
   "source": [
    "# How many infs\n",
    "print(f\"Number of infs: {np.sum(np.isinf(features_X_test))}\")\n",
    "# Which columns have infs\n",
    "cols_with_infs = np.where(np.isinf(features_X_test))[1]\n",
    "cols_with_infs_unique = np.unique(cols_with_infs)\n",
    "print(f\"Columns with infs: {len(cols_with_infs_unique)}\")\n",
    "# Numbers bigger than 10000\n",
    "print(f\"Number of values bigger than 10000: {np.sum(features_X_test > 10000)}\")\n",
    "# Cap everything bigger than 10000 to 10000\n",
    "features_X_test[features_X_test > 10000] = 10000\n",
    "# Numbers smaller than -10000\n",
    "print(f\"Number of values smaller than -10000: {np.sum(features_X_test < -10000)}\")\n",
    "# Cap everything smaller than -10000 to -10000\n",
    "features_X_test[features_X_test < -10000] = -10000\n",
    "# Cap inf to 20000\n",
    "features_X_test[np.isinf(features_X_test)] = 20000\n",
    "# Cap -inf to -20000\n",
    "features_X_test[np.isneginf(features_X_test)] = -20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(features_X_test, columns=feature_names_test)\n",
    "df_test.index.name = \"id\"\n",
    "X_test_save_path = \"/Users/ericschreiber/dev/ETH/AML/Project_1/aml-2023/task2/data/feature_extraction/bioss_X_test.csv\"\n",
    "df_test.to_csv(X_test_save_path, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3411, 81)\n",
      "(3411, 81)\n",
      "(3411, 17807)\n"
     ]
    }
   ],
   "source": [
    "print(features_X_test.shape)\n",
    "print(features_X_test_double.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ericschreiber/dev/ETH/AML/Project_1/aml-2023/task2/feature_extraction/biobss.ipynb Cell 28\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ericschreiber/dev/ETH/AML/Project_1/aml-2023/task2/feature_extraction/biobss.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Number of rows that only contain 0\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ericschreiber/dev/ETH/AML/Project_1/aml-2023/task2/feature_extraction/biobss.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m rows_with_only_0 \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ericschreiber/dev/ETH/AML/Project_1/aml-2023/task2/feature_extraction/biobss.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(features_X_test)):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ericschreiber/dev/ETH/AML/Project_1/aml-2023/task2/feature_extraction/biobss.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mif\u001b[39;00m features_X_test\u001b[39m.\u001b[39miloc[i]\u001b[39m.\u001b[39msum() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ericschreiber/dev/ETH/AML/Project_1/aml-2023/task2/feature_extraction/biobss.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         rows_with_only_0 \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features_X_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Number of rows that only contain 0\n",
    "rows_with_only_0 = 0\n",
    "for i in range(len(features_X_test)):\n",
    "    if features_X_test.iloc[i].sum() == 0:\n",
    "        rows_with_only_0 += 1\n",
    "\n",
    "print(f\"Number of rows that only contain 0: {rows_with_only_0}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
