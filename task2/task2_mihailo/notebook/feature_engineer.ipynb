{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3f8496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hrvanalysis import get_time_domain_features, get_frequency_domain_features\n",
    "from hrvanalysis.preprocessing import get_nn_intervals\n",
    "import biosppy.signals.ecg as ecg\n",
    "from tqdm import tqdm\n",
    "import neurokit2 as nk\n",
    "from sklearn.utils import class_weight\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709a6bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data\"\n",
    "SAMPLING_RATE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad045727",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(f'{DATA_PATH}/X_test.csv')\n",
    "X_train = pd.read_csv(f'{DATA_PATH}/X_train.csv')\n",
    "y_train = pd.read_csv(f'{DATA_PATH}/y_train.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe93ef7",
   "metadata": {},
   "source": [
    "# Merge data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52043d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dataname):\n",
    "    X_test = pd.read_csv(f'../data/{dataname}/X_test.csv')\n",
    "    X_train = pd.read_csv(f'../data/{dataname}/X_train.csv')\n",
    "    return X_train, X_test\n",
    "def concat_data(x1, x2):\n",
    "    concated_x = pd.concat([x1, x2.drop(columns=['id'])], axis=1)\n",
    "    return concated_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffa020a",
   "metadata": {},
   "source": [
    "# hvrtd (Time Domain Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f045c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://aura-healthcare.github.io/hrv-analysis/hrvanalysis.html#hrvanalysis.extract_features.get_time_domain_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21433aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_td_features(signal):\n",
    "#     r_peaks = ecg.engzee_segmenter(signal, SAMPLING_RATE)['rpeaks']\n",
    "    signals, info = nk.ecg_process(signal, sampling_rate=SAMPLING_RATE)\n",
    "    r_peaks = info[\"ECG_R_Peaks\"]\n",
    "    rr_intervals = r_peaks[1:]-r_peaks[:-1]\n",
    "    time_domain_features = get_time_domain_features(rr_intervals)\n",
    "    return time_domain_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683582b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# signal = X_test.loc[155].dropna().to_numpy(dtype='float32')\n",
    "# # signals, info = nk.ecg_process(signal, sampling_rate=SAMPLING_RATE)\n",
    "# # r_peaks = info[\"ECG_R_Peaks\"]\n",
    "# # r_peaks = ecg.engzee_segmenter(signal, SAMPLING_RATE)['rpeaks']\n",
    "# feature_names = [\n",
    "#         \"mean_nni\", \"sdnn\" , \"sdsd\", \"rmssd\", \"median_nni\", \n",
    "#         \"nni_50\", \"pnni_50\", \"nni_20\", \"pnni_20\", \"range_nni\", \n",
    "#         \"cvsd\", \"cvnni\", \"mean_hr\", \"max_hr\", \"min_hr\", \"std_hr\"]\n",
    "# td_features = get_td_features(signal)\n",
    "# feature_vector = []\n",
    "# for fn in feature_names:\n",
    "#     feature_vector.append(td_features[fn])\n",
    "# feature_vector, td_features\n",
    "# # len(r_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab8cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_td_features(data):\n",
    "    feature_names = [\n",
    "        \"mean_nni\", \"sdnn\" , \"sdsd\", \"rmssd\", \"median_nni\", \n",
    "        \"nni_50\", \"pnni_50\", \"nni_20\", \"pnni_20\", \"range_nni\", \n",
    "        \"cvsd\", \"cvnni\", \"mean_hr\", \"max_hr\", \"min_hr\", \"std_hr\"]\n",
    "    feature_vecs = []\n",
    "    error_counts = 0\n",
    "    for i in tqdm(range(len(data))):\n",
    "        signal = data.loc[i].dropna().to_numpy(dtype='float32')\n",
    "        time_domain_features = None\n",
    "        try:\n",
    "            time_domain_features = get_td_features(signal)\n",
    "        except:\n",
    "            pass\n",
    "        feature_vector = []\n",
    "        if time_domain_features is None:\n",
    "            error_counts += 1\n",
    "        for fn in feature_names:\n",
    "            if time_domain_features is None:\n",
    "                feature_vector.append(np.nan)\n",
    "            else:\n",
    "                feature_vector.append(time_domain_features[fn])\n",
    "        feature_vecs.append(feature_vector)\n",
    "    return feature_names, np.array(feature_vecs), error_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7e69ec",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ed107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "td_feature_names, td_features, error_counts = generate_td_features(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0483b7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=td_features, columns=td_feature_names)\n",
    "with open(\"X_train.csv\", \"w\") as f:\n",
    "    f.write(\"id,\"+\",\".join(td_feature_names) + \"\\n\")\n",
    "    for i, d in enumerate(df.to_numpy()):\n",
    "        f.write(f\"{str(i)},\"+\",\".join([str(x) for x in d])+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca13b4c",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e499e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "td_feature_names, td_features, error_counts = generate_td_features(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b390dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=td_features, columns=td_feature_names)\n",
    "with open(\"X_test.csv\", \"w\") as f:\n",
    "    f.write(\"id,\"+\",\".join(td_feature_names) + \"\\n\")\n",
    "    for i, d in enumerate(df.to_numpy()):\n",
    "        f.write(f\"{str(i)},\"+\",\".join([str(x) for x in d])+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2b4e04",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c942cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpqst_X_train, rpqst_X_test = read_data('rpqst')\n",
    "hvr_X_train, hvr_X_test = read_data('hvr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_X_train = concat_data(rpqst_X_train, hvr_X_train)\n",
    "concated_X_test = concat_data(rpqst_X_test, hvr_X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deada859",
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_X_train.to_csv(\"X_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a36b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_X_test.to_csv(\"X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b19a9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e3b652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d91c83d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0b7c77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14255bf1",
   "metadata": {},
   "source": [
    "# HVRAnalysis freq features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba26fda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://aura-healthcare.github.io/hrv-analysis/hrvanalysis.html#hrvanalysis.extract_features.get_frequency_domain_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbfc2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\"total_power\",\"vlf\",\"lf\",\"hf\",\"lf_hf_ratio\",\"lfnu\",\"hfnu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cfbfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(signal, extraction_method):\n",
    "#     r_peaks = ecg.engzee_segmenter(signal, SAMPLING_RATE)['rpeaks']\n",
    "    signals, info = nk.ecg_process(signal, sampling_rate=SAMPLING_RATE)\n",
    "    r_peaks = info[\"ECG_R_Peaks\"]\n",
    "    rr_intervals = r_peaks[1:]-r_peaks[:-1]\n",
    "    features = extraction_method(rr_intervals)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990366a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(data, extraction_method, feature_names):\n",
    "    feature_vecs = []\n",
    "    error_counts = 0\n",
    "    for i in tqdm(range(len(data))):\n",
    "        signal = data.loc[i].dropna().to_numpy(dtype='float32')\n",
    "        features = None\n",
    "        try:\n",
    "            features = get_features(signal, extraction_method)\n",
    "        except:\n",
    "            pass\n",
    "        feature_vector = []\n",
    "        if features is None:\n",
    "            error_counts += 1\n",
    "        for fn in feature_names:\n",
    "            if features is None:\n",
    "                feature_vector.append(np.nan)\n",
    "            else:\n",
    "                feature_vector.append(features[fn])\n",
    "        feature_vecs.append(feature_vector)\n",
    "    return feature_names, np.array(feature_vecs), error_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119986b7",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1ea509",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_X_train = generate_features(X_train, get_frequency_domain_features, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675fe564",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_X_train_df = pd.DataFrame(fd_X_train[1], columns = fd_X_train[0])\n",
    "fd_X_train_df.to_csv(\"X_train.csv\", index_label=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2c01f5",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156e3c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_X_test = generate_features(X_test, get_frequency_domain_features, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd38b0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_X_test_df = pd.DataFrame(fd_X_test[1], columns = fd_X_test[0])\n",
    "fd_X_test_df.to_csv(\"X_test.csv\", index_label=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8b68b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpqst_hvrtd_X_train, rpqst_hvrtd_X_test = read_data('rpqst_hvrtd')\n",
    "hvrfd_X_train, hvrfd_X_test = read_data('hvrfd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2559e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_X_train = concat_data(rpqst_hvrtd_X_train, hvrfd_X_train)\n",
    "concated_X_test = concat_data(rpqst_hvrtd_X_test, hvrfd_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c615a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_X_train.to_csv(\"X_train.csv\", index=False)\n",
    "concated_X_test.to_csv(\"X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30142111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058f3fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94100a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb45e773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9843db92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0dc3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23604590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1cca549",
   "metadata": {},
   "source": [
    "# Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc566235",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = X_test.loc[5].dropna().to_numpy(dtype='float32')\n",
    "signals, info = nk.ecg_process(signal, sampling_rate=SAMPLING_RATE)\n",
    "rpeaks = info[\"ECG_R_Peaks\"]\n",
    "cleaned_signal = signals[\"ECG_Clean\"]\n",
    "\n",
    "_, waves_peak = nk.ecg_delineate(cleaned_signal, rpeaks, sampling_rate=SAMPLING_RATE, method=\"peak\")\n",
    "\n",
    "intervals = np.array(waves_peak[\"ECG_P_Onsets\"][1:])-np.array(waves_peak[\"ECG_P_Onsets\"][:-1])\n",
    "np.mean(intervals[~np.isnan(intervals)])\n",
    "\n",
    "def intervals_mean_std(l1, l2):\n",
    "    intervals = np.array(l2)-np.array(l1)\n",
    "    return np.mean(intervals[~np.isnan(intervals)]), np.std(intervals[~np.isnan(intervals)])\n",
    "\n",
    "feature_names = waves_peak.keys()\n",
    "intervals_stats = []\n",
    "for k in feature_names:\n",
    "    l1 = waves_peak[k]\n",
    "    l2 = rpeaks\n",
    "    mean, std = intervals_mean_std(l1, l2)\n",
    "    intervals_stats.append(mean)\n",
    "    intervals_stats.append(std)\n",
    "\n",
    "feature_names, intervals_stats\n",
    "\n",
    "# ['ECG_P_Peaks', 'ECG_Q_Peaks', 'ECG_S_Peaks', 'ECG_T_Peaks', 'ECG_P_Onsets', 'ECG_T_Offsets']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5d932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intervals_mean_std(l1, l2):\n",
    "    intervals = np.array(l2)-np.array(l1)\n",
    "    return np.mean(intervals[~np.isnan(intervals)]), np.std(intervals[~np.isnan(intervals)])\n",
    "\n",
    "def generate_interval_features(data):\n",
    "    keys = ['ECG_P_Peaks', 'ECG_Q_Peaks', 'ECG_S_Peaks', 'ECG_T_Peaks', 'ECG_P_Onsets', 'ECG_T_Offsets']\n",
    "    feature_names = [\n",
    "        'pr_mean', 'pr_std', \n",
    "        'qr_mean', 'qr_std',\n",
    "        'sr_mean', 'sr_std',\n",
    "        'tr_mean', 'tr_std',\n",
    "        'por_mean', 'por_std',\n",
    "        'tor_mean', 'tor_std',\n",
    "    ]\n",
    "    feature_vecs = []\n",
    "    indices = []\n",
    "    error_counts = 0\n",
    "    for i in tqdm(range(len(data))):\n",
    "        signal = data.loc[i].dropna().to_numpy(dtype='float32')\n",
    "        feature_vector = None\n",
    "\n",
    "        try:\n",
    "            signals, info = nk.ecg_process(signal, sampling_rate=SAMPLING_RATE)\n",
    "            rpeaks = info[\"ECG_R_Peaks\"]\n",
    "            cleaned_signal = signals[\"ECG_Clean\"]\n",
    "\n",
    "            _, waves_peak = nk.ecg_delineate(cleaned_signal, rpeaks, sampling_rate=SAMPLING_RATE, method=\"peak\")\n",
    "\n",
    "            intervals_stats = []\n",
    "            for k in keys:\n",
    "                mean, std = intervals_mean_std(waves_peak[k], rpeaks)\n",
    "                intervals_stats.append(mean)\n",
    "                intervals_stats.append(std)\n",
    "            feature_vector = intervals_stats\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if feature_vector is None:\n",
    "            error_counts += 1\n",
    "            feature_vector = [np.nan]*len(feature_names)\n",
    "        feature_vecs.append(feature_vector)\n",
    "        indices.append(i)\n",
    "        \n",
    "    return feature_names, np.array(feature_vecs), error_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57910354",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names, features, error_counts = generate_interval_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba7b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_X_train_df = pd.DataFrame(features, columns = feature_names)\n",
    "fd_X_train_df.to_csv(\"X_train.csv\", index_label=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf20710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names, features, error_counts = generate_interval_features(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9885e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_X_test_df = pd.DataFrame(features, columns = feature_names)\n",
    "fd_X_test_df.to_csv(\"X_test.csv\", index_label=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851505a5",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ac936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1 = read_data('rpqst_hvrtd_hvrfd')\n",
    "X_train2, X_test2 = read_data('itv')\n",
    "concated_X_train = concat_data(X_train1, X_train2)\n",
    "concated_X_test = concat_data(X_test1, X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcf0627",
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_X_train.to_csv(\"X_train.csv\", index=False)\n",
    "concated_X_test.to_csv(\"X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3e0771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa992e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86102199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7107c6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267e82a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15f22c2a",
   "metadata": {},
   "source": [
    "# pyHRV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56228f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhrv.tools as tools\n",
    "from pyhrv.hrv import hrv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e3b2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_names = ['nni_counter', 'nni_mean', 'nni_min', 'nni_max', 'hr_mean', 'hr_min', 'hr_max', 'hr_std', \n",
    "#            'nni_diff_mean', 'nni_diff_min', 'nni_diff_max', 'sdnn', 'rmssd', \n",
    "#            'sdsd', 'nn50', 'pnn50', 'nn20', 'pnn20', 'sd1', 'sd2', 'sd_ratio', 'ellipse_area', 'sampen']\n",
    "# for k in fl_keys:\n",
    "#     print(k, extracted[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1eedad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%capture\n",
    "# signal = X_test.loc[0].dropna().to_numpy(dtype='float32')\n",
    "# signals, info = nk.ecg_process(signal, sampling_rate=SAMPLING_RATE)\n",
    "# # rpeaks = info[\"ECG_R_Peaks\"]\n",
    "# # rpeaks\n",
    "# signals, rpeaks = ecg.ecg(signal, show=False)[1:3]\n",
    "# rpeaks\n",
    "# nni = tools.nn_intervals(rpeaks)\n",
    "# extracted = hrv(nni, rpeaks, signals, SAMPLING_RATE)\n",
    "# feature_vector = np.array([extracted[k] for k in feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d3590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_interval_features(data, file_path, start=0):\n",
    "    feature_names = ['nni_counter', 'nni_mean', 'nni_min', 'nni_max', 'hr_mean', 'hr_min', 'hr_max', 'hr_std', \n",
    "           'nni_diff_mean', 'nni_diff_min', 'nni_diff_max', 'sdnn', 'rmssd', \n",
    "           'sdsd', 'nn50', 'pnn50', 'nn20', 'pnn20', 'sd1', 'sd2', 'sd_ratio'] #, 'ellipse_area', 'sampen']\n",
    "#     feature_vecs = []\n",
    "    error_counts = 0\n",
    "    \n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(\"id,\"+\",\".join(feature_names) + \"\\n\")\n",
    "        \n",
    "    for i in tqdm(range(start, len(data))):\n",
    "        signal = data.loc[i].dropna().to_numpy(dtype='float32')\n",
    "        feature_vector = None\n",
    "\n",
    "        try:\n",
    "            signals, rpeaks = ecg.ecg(signal, show=False)[1:3]\n",
    "            nni = tools.nn_intervals(rpeaks)\n",
    "            extracted = hrv(nni, rpeaks, signals, SAMPLING_RATE)\n",
    "            feature_vector = np.array([extracted[k] for k in feature_names])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if feature_vector is None:\n",
    "            error_counts += 1\n",
    "            feature_vector = [np.nan]*len(feature_names)\n",
    "#         feature_vecs.append(feature_vector)\n",
    "\n",
    "        with open(file_path, \"a\") as f:\n",
    "            f.write(f\"{str(i)},\"+\",\".join([str(x) for x in feature_vector])+\"\\n\")\n",
    "\n",
    "#     return feature_names, np.array(feature_vecs), error_counts\n",
    "    return feature_names, error_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ce6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names, error_counts = generate_interval_features(X_train, \"X_train_cont.csv\", start=2789)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7b280d",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5729b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1 = read_data('rpqst_hvrtd_hvrfd_itv')\n",
    "X_train2, X_test2 = read_data('pyhrv')\n",
    "concated_X_train = concat_data(X_train1, X_train2)\n",
    "concated_X_test = concat_data(X_test1, X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0eb7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_X_train.to_csv(\"X_train.csv\", index=False)\n",
    "concated_X_test.to_csv(\"X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f2e200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a37b917",
   "metadata": {},
   "source": [
    "# Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5a2efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [int(i) for i in np.unique(y_train)]\n",
    "cw = class_weight.compute_class_weight(class_weight='balanced', classes=classes, y=y_train.to_numpy().reshape(-1))\n",
    "weights = dict(zip(classes,cw))\n",
    "weights\n",
    "# with open('weights.json', 'w') as f:\n",
    "#     json.dump(weights, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6050e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_count(df, cls):\n",
    "    return len(df.loc[y_train.y==cls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c123d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = []\n",
    "for i in range(4):\n",
    "    count = cls_count(y_train, i)\n",
    "    counts.append(count)\n",
    "counts = np.array(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ea8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cls_count = np.max(counts)\n",
    "weights = max_cls_count / counts\n",
    "with open('weights.npy', 'wb') as f:\n",
    "    np.save(f, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b81bf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../score/weights.npy', 'rb') as f:\n",
    "    weights = np.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
